{
 "metadata": {
  "name": "",
  "signature": "sha256:0ece47445e0e4d783d9d44a01cb5e18dcd22ce26d44c046aeee44822bb6b1ea1"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#iPython Cookbook - Monte Carlo II\n",
      ">Generating a Monte Carlo vector using Cholesky Decomposition"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Theory\n",
      "\n",
      "Before we go into the implementation, a bit of theory on Monte Carlo and linear algebra, and in particular the Cholesky decomposition. Firstly Monte Carlo: assume we have a Standard Gaussian vector $Z=(Z_i)$ and we want a general Gaussian vector $X=(X_i)$ with correlation matrix $C = (C_{ij})$. Because everything is linear we know that $X$ will be of the form $X = Z \\cdot M$ with some matrix $M$ (we assume the $X$ have zero expectation for simplicity; also we multiply vectors from the left because we prefer row vectors).\n",
      "\n",
      "Assuming that we have such matrix M what is the corresponding correlation matrix $C^M$? In order to find out we need to calculate \n",
      "$$\n",
      "E[X_iX_j] = \\sum_{\\mu\\nu} M_{\\mu i} M_{\\nu j} E[Z_\\mu Z_\\nu] = \\sum_{\\mu} M_{\\mu i} M_{\\mu j} = (M^tM)_{ij}\n",
      "$$\n",
      "ie we find that the covariance matrix is the *square* of $M$ (in the matrix sense, ie $M^tM$ where $M^t$ is the transposed matrix, ie with rows and columns interchanged). So if we want to generate a vector $X$ with covariance $C$ what we effectively need is a matrix $M$ such that $C= M^tM$.\n",
      "\n",
      "Enter *Cholesky decomposition*: in a nutshell, if a matrix $M$ is symmetric and positive definite (with strictly positive eigenvaluesl; as every non-degenerate covariance matrix is) then there is a unique decomposition $C = L^tL$ with the $L$ being a triangular matrix."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Implementation\n",
      "### Generating a covariance matrix\n",
      "First we generat a covariance matrix. This is not entirely trivial - the matrix must be symmetric and positive definite - and one way going about is to simply write $C = R^tR$ where $R$ is *any* random matrix (note that this is not a particularly good covariance matrix, because it is pretty close to the one-systemic-factor model)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d = 4\n",
      "R = np.random.uniform(-1,1,(d,d))+np.eye(d)\n",
      "C = np.dot(R.T, R)\n",
      "#C, sort(eigvalsh(C))[::-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Decomposing the covariance matrix\n",
      "We are given a covariance matrix $C$ and we want to find a matrix $M$ such that $M^tM=C$. One such matrix is given by running a Cholesky decomposition that is implemented in Python as `scipy.linalg.cholesky()`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.linalg import cholesky\n",
      "M = cholesky(C)\n",
      "M"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "array([[ 1.18580307,  0.35238349,  1.1148574 , -0.43031757],\n",
        "       [ 0.        ,  0.93486624, -1.55116164,  0.35624587],\n",
        "       [ 0.        ,  0.        ,  1.22910763,  1.02804289],\n",
        "       [ 0.        ,  0.        ,  0.        ,  1.17002493]])"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Generating $z$\n",
      "We now generate our Standard Gaussian $z$, as usual one row being one observation ($N$ is the number of rows)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "N = 10000\n",
      "z = np.random.standard_normal((N, d))\n",
      "z"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "array([[-0.7823201 , -0.12360443, -0.96780842,  0.13517212],\n",
        "       [ 0.53335478, -0.81588521, -0.60080122,  0.67694351],\n",
        "       [-1.21479747,  0.33155255,  0.42321467,  0.56672363],\n",
        "       ..., \n",
        "       [-1.27686341, -0.93916387, -0.07284885, -0.36030967],\n",
        "       [ 0.27073261,  0.95586545, -0.4922071 ,  0.20966966],\n",
        "       [-0.02958598,  0.16729888, -0.97722575, -0.57274249]])"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Generating $x$\n",
      "We now generate our $x$ by multiplying $z \\cdot M$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = np.dot(z,M)\n",
      "x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "array([[-0.92767758, -0.3912303 , -1.86998562, -0.54418129],\n",
        "       [ 0.63245373, -0.57479812,  1.12173499, -0.34577631],\n",
        "       [-1.44051057, -0.11811729, -1.34844116,  1.73902654],\n",
        "       ..., \n",
        "       [-1.51410855, -1.32793819, -0.05626472, -0.28157953],\n",
        "       [ 0.32103556,  0.98900805, -1.78584907, -0.03666916],\n",
        "       [-0.03508315,  0.14597646, -1.49360738, -1.60242208]])"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Check\n",
      "We now check that the ex-post covariance matrix $C1$ is reasonably close to the ex-ante matrix $C$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "C1 = np.cov(x, rowvar=0, bias=1)\n",
      "C1, C, sort(eigvalsh(C1))[::-1],sort(eigvalsh(C))[::-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "(array([[ 1.35513285,  0.38370626,  1.32505864, -0.47565306],\n",
        "        [ 0.38370626,  0.95954664, -1.01692056,  0.21841181],\n",
        "        [ 1.32505864, -1.01692056,  5.12114778,  0.27754752],\n",
        "        [-0.47565306,  0.21841181,  0.27754752,  2.82800237]]),\n",
        " array([[ 1.40612893,  0.41785743,  1.32200133, -0.51027189],\n",
        "        [ 0.41785743,  0.99814902, -1.05727131,  0.18140543],\n",
        "        [ 1.32200133, -1.05727131,  5.15971501,  0.23123771],\n",
        "        [-0.51027189,  0.18140543,  0.23123771,  2.73791486]]),\n",
        " array([ 5.70069873,  2.96750667,  1.49782554,  0.0977987 ]),\n",
        " array([ 5.74687105,  2.89822579,  1.55892866,  0.09788232]))"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Licence and version\n",
      "*(c) Stefan Loesch / oditorium 2014; all rights reserved \n",
      "([license](https://github.com/oditorium/blog/blob/master/LICENSE))*"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "print(sys.version)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3.4.0 (default, Apr 11 2014, 13:05:11) \n",
        "[GCC 4.8.2]\n"
       ]
      }
     ],
     "prompt_number": 7
    }
   ],
   "metadata": {}
  }
 ]
}